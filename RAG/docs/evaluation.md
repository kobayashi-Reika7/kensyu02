# RAG精度評価ガイド

## 概要

このドキュメントでは、OnsenRAGの精度を評価するための方法と基準を解説します。

---

## 評価基準（3つの観点）

| 観点 | 内容 | 判定方法 |
|------|------|----------|
| **正確性** | 正解チャンクを含んでいるか | 期待されるチャンクが検索結果に含まれるか |
| **ノイズ** | 余計なチャンクを混ぜていないか | 無関係な情報が回答に混入していないか |
| **ハルシネーション** | 存在しない情報を生成していないか | テキストにない情報を「作って」いないか |

---

## 悪いRAG vs 良いRAG の比較

### 想定質問: 「冬におすすめの温泉地は？」

### 悪いRAGの例

**原因:**
- チャンクが大きすぎる
- 検索結果が曖昧
- 関係ない文章も一緒にLLMに渡している

**検索で拾われたチャンク:**
```
■ 草津温泉（群馬県）
草津温泉は日本三名泉のひとつとされる温泉地です。
自然湧出量は日本一を誇ります。
泉質は強い酸性泉で、殺菌作用が高いとされています。
草津温泉の中心には湯畑があります。
```

**LLMの回答（ありがち）:**
> 草津温泉は有名な温泉地で、観光スポットも多くおすすめです。

- 「冬におすすめ」という根拠がない
- 季節情報を含まないチャンクが検索された

### 良いRAGの例

**改善点:**
- チャンクを意味単位で分割
- 季節情報を含むチャンクが検索ヒット
- 質問と文脈が一致

**正しく拾われたチャンク:**
```
■ 季節ごとの温泉の楽しみ方
冬は雪景色を眺めながらの露天風呂が人気です。
草津温泉などの山間部の温泉地では冬ならではの景色を楽しめます。
```

**LLMの回答（理想）:**
> 冬には、雪景色を楽しめる草津温泉のような山間部の温泉地がおすすめです。
> 露天風呂から雪景色を眺めながら入浴できます。

- 質問にドンピシャの回答
- 文脈に基づいた根拠のある回答

---

## 質問ごとの正解チャンク解説（評価表）

| 質問 | 正解チャンク | 評価ポイント |
|------|-------------|-------------|
| 温泉とは何ですか？ | 「■ 温泉とは」 | 定義がそのまま含まれている |
| 美肌の湯は？ | 「■ 炭酸水素塩泉」 | 美肌という表現が明示 |
| 冬におすすめの温泉地は？ | 「■ 季節ごとの温泉の楽しみ方（冬）」 | 季節条件が一致 |
| 東京から行きやすい温泉地は？ | 「■ 箱根温泉」 | アクセス情報あり |
| 湯めぐりできる温泉地は？ | 「■ 別府温泉」 | 湧出量・多様性の記述 |
| 刺激が少ない泉質は？ | 「■ 単純温泉」 | 明確な特徴説明 |

---

## 評価の実行方法

### Python スクリプトで一括評価

```python
from src.onsen_rag import OnsenRAG

rag = OnsenRAG()
rag.load_from_data_folder()  # 全データを読み込み
results = rag.evaluate()     # 14問の自動評価
```

### API経由で検索精度を確認

```bash
# 検索結果のみ確認（LLM回答なし・高速）
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{"question": "冬におすすめの温泉地は？"}'

# 完全な回答を取得
curl -X POST http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "冬におすすめの温泉地は？"}'
```

---

## 検索パイプラインの精度確認

OnsenRAG の3段階パイプラインでは、各段階のログが出力されます:

```
[STEP1] 類似度検索 location=kusatsu | semantic=10件 + BM25=10件 → RRF統合=15件
[RERANK] 15件をCrossEncoderでスコアリング → 15件
  [1] CE_score=2.3456 chunk_id=kusatsu_042
  [2] CE_score=1.8901 chunk_id=kusatsu_015
[LLM_EXTRACT] 15件 → LLM評価で上位5件を抽出
  [1] LLM=9/10 CE=2.3456 chunk_id=kusatsu_042
[FINAL] スコア統合（CE×0.4 + LLM×0.6）→ 上位3件を最終選定
```

各段階で精度を確認できるポイント:
- **Step 1**: 温泉地フィルタが正しく効いているか
- **Re-rank**: CrossEncoderスコアが高い候補が上位に来ているか
- **LLM抽出**: LLMが質問の意図を理解し、関連度の高い候補を選んでいるか
- **最終選定**: 信頼度閾値で低品質候補が除外されているか

---

## チャンクサイズと精度の関係

| チャンクサイズ | メリット | デメリット |
|---------------|---------|-----------|
| 小さい（100-300 tokens） | ピンポイントな情報取得 | 文脈が不足する場合がある |
| 中くらい（400-600 tokens） | バランスが良い | - |
| 大きい（700-1000 tokens） | 文脈が豊富 | ノイズが混入しやすい |

### OnsenRAGの設定

- **chunk_size: 600 tokens** （generalプリセット）
- **chunk_overlap: 75 tokens** （12.5%、段落間の接続を保持）

---

## RAG教材としてのポイント

| 特徴 | なぜRAGに適しているか |
|------|---------------------|
| 情報が分散している | 検索（Retrieval）が効く |
| 条件付き質問が多い | RAGでの絞り込みが必須 |
| 嘘をつくとすぐ分かる | 精度評価がしやすい |

### 研修での決め台詞

> **RAGは「AIに知識を覚えさせる技術」ではない。**
> **「必要な情報を正しく探させる技術」。**

---

## デモで見せると効果的なポイント

1. **Vector DBなし** → 的外れ回答
2. **Vector DBあり** → 根拠付き回答
3. **チャンクサイズを変える** → 精度が変わる

これらを順番に見せることで、RAGの仕組みと効果を実感できます。
