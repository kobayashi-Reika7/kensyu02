"""
HybridSearchRAG - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢RAGã‚·ã‚¹ãƒ†ãƒ 
================================================
2ã¤ã®ç•°ãªã‚‹æ¤œç´¢æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ï¼š

  ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ï¼‰
    â†’ æ„å‘³çš„ãªé¡ä¼¼æ€§ã§æ¤œç´¢ï¼ˆã€ŒçŠ¬ã€ã§æ¤œç´¢â†’ã€Œãƒšãƒƒãƒˆã€ã‚‚ãƒ’ãƒƒãƒˆï¼‰

  + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆBM25ï¼‰
    â†’ å˜èªã®ä¸€è‡´åº¦ã§æ¤œç´¢ï¼ˆã€ŒçŠ¬ã€ã§æ¤œç´¢â†’ã€ŒçŠ¬ã€ã‚’å«ã‚€æ–‡æ›¸ãŒãƒ’ãƒƒãƒˆï¼‰

  = ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆEnsembleRetrieverï¼‰
    â†’ ä¸¡æ–¹ã®çµæœã‚’é‡ã¿ä»˜ã‘ã§çµ±åˆã—ã€ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„æ¤œç´¢ã‚’å®Ÿç¾
"""

import os
from dotenv import load_dotenv
from src.text_splitter_utils import create_token_text_splitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_classic.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_classic.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate
from langchain_openai import OpenAI
from langchain_core.documents import Document

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


class HybridSearchRAG:
    """
    ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢RAGã‚·ã‚¹ãƒ†ãƒ 

    ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ï¼‰ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆBM25ï¼‰ã‚’
    çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

    ãªãœãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãŒæœ‰åŠ¹ã‹ï¼š
    - ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢: æ„å‘³ã¯ç†è§£ã™ã‚‹ãŒã€å›ºæœ‰åè©ã«å¼±ã„
    - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: å›ºæœ‰åè©ã«å¼·ã„ãŒã€é¡ç¾©èªã«å¼±ã„
    - ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€äº’ã„ã®å¼±ç‚¹ã‚’è£œå®Œã§ãã‚‹

    ä½¿ç”¨ä¾‹:
        rag = HybridSearchRAG()
        rag.load_documents(["ãƒ†ã‚­ã‚¹ãƒˆ1", "ãƒ†ã‚­ã‚¹ãƒˆ2"])
        result = rag.query("è³ªå•å†…å®¹")
    """

    def __init__(self, semantic_weight: float = 0.5):
        """
        HybridSearchRAGã®åˆæœŸåŒ–

        Args:
            semantic_weight: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®é‡ã¿ï¼ˆ0.0ã€œ1.0ï¼‰
                            ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0.5ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åŒç­‰ã«æ‰±ã†ï¼‰
                            0.7ã«ã™ã‚‹ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’é‡è¦–
                            0.3ã«ã™ã‚‹ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’é‡è¦–
        """
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®é‡ã¿é…åˆ†
        self.semantic_weight = semantic_weight
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®é‡ã¿ã¯æ®‹ã‚Šã®å€¤
        self.keyword_weight = 1.0 - semantic_weight

        # Embeddingãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        self.embeddings = HuggingFaceEmbeddings(
            model_name="intfloat/multilingual-e5-base"
        )

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        self.vectorstore = None
        self.documents = []  # BM25 Retrieverç”¨ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿æŒ

        # LLMã®åˆæœŸåŒ–
        self.llm = OpenAI(
            temperature=0,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )

    def load_documents(self, texts: list[str]) -> None:
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç”¨ã«æº–å‚™

        å‡¦ç†ã®æµã‚Œï¼š
        1. ãƒ†ã‚­ã‚¹ãƒˆã‚’Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        2. ãƒãƒ£ãƒ³ã‚¯åŒ–ã—ã¦åˆ†å‰²
        3. ãƒ™ã‚¯ãƒˆãƒ«DBï¼ˆChromaï¼‰ã«ä¿å­˜ â†’ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ç”¨
        4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’ä¿æŒ â†’ BM25ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨

        Args:
            texts: èª­ã¿è¾¼ã‚€ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        documents = [Document(page_content=text) for text in texts]

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹ã§åˆ†å‰²
        text_splitter = create_token_text_splitter(
            document_type="general",
            separators=["\n\n", "\n", "ã€‚", "ã€", " ", ""],
        )
        splits = text_splitter.split_documents(documents)

        # åˆ†å‰²å¾Œã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿æŒï¼ˆBM25 Retrieverç”¨ï¼‰
        self.documents = splits

        # ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ç”¨ï¼‰
        self.vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=self.embeddings
        )

        print(f"âœ… {len(splits)}ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢å¯¾å¿œï¼‰")

    def _create_ensemble_retriever(self, k: int = 4) -> EnsembleRetriever:
        """
        ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’çµ±åˆã—ãŸRetrieverã‚’ä½œæˆ

        Args:
            k: å„æ¤œç´¢æ‰‹æ³•ãŒè¿”ã™çµæœã®ä»¶æ•°

        Returns:
            EnsembleRetriever: çµ±åˆã•ã‚ŒãŸRetriever

        å†…éƒ¨å‡¦ç†ï¼š
        - BM25Retriever: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾é »åº¦ã§é–¢é€£åº¦ã‚’è¨ˆç®—
        - VectorStoreRetriever: ãƒ™ã‚¯ãƒˆãƒ«ã®è·é›¢ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰ã§é–¢é€£åº¦ã‚’è¨ˆç®—
        - EnsembleRetriever: ä¸¡æ–¹ã®çµæœã‚’é‡ã¿ä»˜ã‘ã§çµ±åˆ
        """
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨ã®BM25 Retriever
        # BM25: ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®å˜èªã®å‡ºç¾é »åº¦ã«åŸºã¥ããƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        bm25_retriever = BM25Retriever.from_documents(self.documents)
        bm25_retriever.k = k  # ä¸Šä½kä»¶ã‚’å–å¾—

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã®Retriever
        vector_retriever = self.vectorstore.as_retriever(
            search_kwargs={"k": k}
        )

        # ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ãŸEnsemble Retriever
        # weights: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®é‡ã¿é…åˆ†
        ensemble_retriever = EnsembleRetriever(
            retrievers=[vector_retriever, bm25_retriever],
            weights=[self.semantic_weight, self.keyword_weight]
        )

        return ensemble_retriever

    def query(self, question: str, k: int = 4) -> dict:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã§å›ç­”ã‚’ç”Ÿæˆ

        ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®ä¸¡æ–¹ã‚’ä½¿ã£ã¦
        é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã€LLMã§å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            question: è³ªå•æ–‡
            k: æ¤œç´¢çµæœã®ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4ä»¶ï¼‰

        Returns:
            dict: å›ç­”çµæœ
                - "result": LLMãŒç”Ÿæˆã—ãŸå›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒæœªä½œæˆã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if self.vectorstore is None:
            raise ValueError(
                "ãƒ‡ãƒ¼ã‚¿ãŒæœªèª­ã¿è¾¼ã¿ã§ã™ã€‚"
                "å…ˆã«load_documents()ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚"
            )

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Retrieverã‚’ä½œæˆ
        ensemble_retriever = self._create_ensemble_retriever(k=k)

        # æ—¥æœ¬èªå¯¾å¿œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        template = """ã‚ãªãŸã¯å°‚é–€çš„ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ–‡è„ˆã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€æ–‡è„ˆã€‘
{context}

ã€è³ªå•ã€‘
{question}

ã€å›ç­”ã®éš›ã®æ³¨æ„ç‚¹ã€‘
ãƒ»æ–‡è„ˆã«æ›¸ã‹ã‚Œã¦ã„ã‚‹äº‹å®Ÿã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹
ãƒ»æ¨æ¸¬ã‚„ä¸€èˆ¬çŸ¥è­˜ã‚’æ··ãœãªã„
ãƒ»ç­”ãˆã‚‰ã‚Œãªã„å ´åˆã¯æ­£ç›´ã«ãã®æ—¨ã‚’ä¼ãˆã‚‹

ã€å›ç­”ã€‘"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        # QAãƒã‚§ãƒ¼ãƒ³ä½œæˆ
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=ensemble_retriever,
            chain_type_kwargs={"prompt": prompt}
        )

        result = qa_chain({"query": question})
        return result

    def compare_search_modes(
        self, question: str, k: int = 4
    ) -> dict[str, list[Document]]:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®3æ‰‹æ³•ã§æ¤œç´¢ã—ã€å›åç‡ã‚’æ¯”è¼ƒã™ã‚‹ã€‚

        ç²¾åº¦ã®æ¸¬å®š: å„æ‰‹æ³•ã®çµæœã‚’æ¯”è¼ƒã—ã¦ã€ã©ã‚ŒãŒæœ€é©ã‹æ¤œè¨¼ã™ã‚‹ãƒ’ãƒ³ãƒˆã€‚

        Args:
            question: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: å„æ‰‹æ³•ã®å–å¾—ä»¶æ•°

        Returns:
            dict: {"keyword": [...], "semantic": [...], "hybrid": [...]}
        """
        if self.vectorstore is None:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒæœªèª­ã¿è¾¼ã¿ã§ã™ã€‚")

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆBM25ï¼‰ã®ã¿
        bm25 = BM25Retriever.from_documents(self.documents)
        bm25.k = k
        keyword_docs = bm25.invoke(question)

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã®ã¿
        vec_ret = self.vectorstore.as_retriever(search_kwargs={"k": k})
        semantic_docs = vec_ret.invoke(question)

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
        ensemble = self._create_ensemble_retriever(k=k)
        hybrid_docs = ensemble.invoke(question)

        return {
            "keyword": keyword_docs,
            "semantic": semantic_docs,
            "hybrid": hybrid_docs,
        }

    def search_only(self, question: str, k: int = 4) -> list:
        """
        å›ç­”ç”Ÿæˆãªã—ã§ã€æ¤œç´¢çµæœã®ã¿ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ»æ¤œè¨¼ç”¨ï¼‰

        æ¤œç´¢ç²¾åº¦ã‚’ç¢ºèªã—ãŸã„æ™‚ã«ä½¿ç”¨ã€‚
        ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãã‚Œãã‚Œã®çµæœã‚’æ¯”è¼ƒå¯èƒ½ã€‚

        Args:
            question: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: å–å¾—ä»¶æ•°

        Returns:
            list: æ¤œç´¢çµæœã®Documentãƒªã‚¹ãƒˆ
        """
        if self.vectorstore is None:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒæœªèª­ã¿è¾¼ã¿ã§ã™ã€‚")

        ensemble_retriever = self._create_ensemble_retriever(k=k)
        results = ensemble_retriever.invoke(question)

        # æ¤œç´¢çµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
        print(f"ğŸ” ã€Œ{question}ã€ã®æ¤œç´¢çµæœ: {len(results)}ä»¶")
        for i, doc in enumerate(results):
            # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯100æ–‡å­—ã§åˆ‡ã‚Šè©°ã‚ã¦è¡¨ç¤º
            preview = doc.page_content[:100] + "..." \
                if len(doc.page_content) > 100 else doc.page_content
            print(f"  [{i+1}] {preview}")

        return results
